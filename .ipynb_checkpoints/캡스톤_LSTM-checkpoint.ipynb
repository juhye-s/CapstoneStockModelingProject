{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f801967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "class ForecastLSTM:\n",
    "    def __init__(self, random_seed: int = 1234):\n",
    "        self.random_seed = random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f603af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dataset(self, df: pd.DataFrame) -> np.array:\n",
    "    # y 컬럼을 데이터프레임의 맨 마지막 위치로 이동\n",
    "    if \"y\" in df.columns:\n",
    "        df = df.drop(columns=[\"y\"]).assign(y=df[\"y\"])\n",
    "    else:\n",
    "        raise KeyError(\"Not found target column 'y' in dataset.\")\n",
    "    \n",
    "    # shape 변경\n",
    "    dataset = df.values.reshape(df.shape)\n",
    "    return dataset\n",
    "\n",
    "ForecastLSTM.reshape_dataset = reshape_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8380c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(\n",
    "    self, dataset: np.array, seq_len: int, steps: int, single_output: bool\n",
    ") -> tuple:\n",
    "\n",
    "    # feature와 y 각각 sequential dataset을 반환할 리스트 생성\n",
    "    X, y = list(), list()\n",
    "    # sequence length와 step에 따라 sequential dataset 생성\n",
    "    for i, _ in enumerate(dataset):\n",
    "        idx_in = i + seq_len\n",
    "        idx_out = idx_in + steps\n",
    "        if idx_out > len(dataset):\n",
    "            break\n",
    "        seq_x = dataset[i:idx_in, :-1]\n",
    "        if single_output:\n",
    "            seq_y = dataset[idx_out - 1 : idx_out, -1]\n",
    "        else:\n",
    "            seq_y = dataset[idx_in:idx_out, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "ForecastLSTM.split_sequences = split_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be76ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid_dataset(\n",
    "    self,\n",
    "    df: pd.DataFrame,\n",
    "    seq_len: int,\n",
    "    steps: int,\n",
    "    single_output: bool,\n",
    "    validation_split: float = 0.3,\n",
    "    verbose: bool = True,\n",
    ") -> tuple:\n",
    "    # dataframe을 numpy array로 reshape\n",
    "    dataset = self.reshape_dataset(df=df)\n",
    "\n",
    "    # feature와 y를 sequential dataset으로 분리\n",
    "    X, y = self.split_sequences(\n",
    "        dataset=dataset,\n",
    "        seq_len=seq_len,\n",
    "        steps=steps,\n",
    "        single_output=single_output,\n",
    "    )\n",
    "\n",
    "    # X, y에서 validation dataset 분리\n",
    "    dataset_size = len(X)\n",
    "    train_size = int(dataset_size * (1 - validation_split))\n",
    "    X_train, y_train = X[:train_size, :], y[:train_size, :]\n",
    "    X_val, y_val = X[train_size:, :], y[train_size:, :]\n",
    "    if verbose:\n",
    "        print(f\" >>> X_train: {X_train.shape}\")\n",
    "        print(f\" >>> y_train: {y_train.shape}\")\n",
    "        print(f\" >>> X_val: {X_val.shape}\")\n",
    "        print(f\" >>> y_val: {y_val.shape}\")\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n",
    "ForecastLSTM.split_train_valid_dataset = split_train_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20013313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_lstm_model(\n",
    "    self,\n",
    "    seq_len: int,\n",
    "    n_features: int,\n",
    "    lstm_units: list,\n",
    "    learning_rate: float,\n",
    "    dropout: float,\n",
    "    steps: int,\n",
    "    metrics: str,\n",
    "    single_output: bool,\n",
    "    last_lstm_return_sequences: bool = False,\n",
    "    dense_units: list = None,\n",
    "    activation: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    LSTM 네트워크를 생성한 결과를 반환한다.\n",
    "\n",
    "    :param seq_len: Length of sequences. (Look back window size)\n",
    "    :param n_features: Number of features. It requires for model input shape.\n",
    "    :param lstm_units: Number of cells each LSTM layers.\n",
    "    :param learning_rate: Learning rate.\n",
    "    :param dropout: Dropout rate.\n",
    "    :param steps: Length to predict.\n",
    "    :param metrics: Model loss function metric.\n",
    "    :param single_output: Whether 'yhat' is a multiple value or a single value.\n",
    "    :param last_lstm_return_sequences: Last LSTM's `return_sequences`. Allow when `single_output=False` only.\n",
    "    :param dense_units: Number of cells each Dense layers. It adds after LSTM layers.\n",
    "    :param activation: Activation function of Layers.\n",
    "    \"\"\"\n",
    "    tf.random.set_seed(self.random_seed)\n",
    "    model = Sequential()\n",
    "\n",
    "    if len(lstm_units) > 1:\n",
    "        # LSTM -> ... -> LSTM -> Dense(steps)\n",
    "        model.add(\n",
    "            LSTM(\n",
    "                units=lstm_units[0],\n",
    "                activation=activation,\n",
    "                return_sequences=True,\n",
    "                input_shape=(seq_len, n_features),\n",
    "            )\n",
    "        )\n",
    "        lstm_layers = lstm_units[1:]\n",
    "        for i, n_units in enumerate(lstm_layers, start=1):\n",
    "            if i == len(lstm_layers):\n",
    "                if single_output:\n",
    "                    return_sequences = False\n",
    "                else:\n",
    "                    return_sequences = last_lstm_return_sequences\n",
    "                model.add(\n",
    "                    LSTM(\n",
    "                        units=n_units,\n",
    "                        activation=activation,\n",
    "                        return_sequences=return_sequences,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                model.add(\n",
    "                    LSTM(\n",
    "                        units=n_units,\n",
    "                        activation=activation,\n",
    "                        return_sequences=True,\n",
    "                    )\n",
    "                )\n",
    "    else:\n",
    "        # LSTM -> Dense(steps)\n",
    "        if single_output:\n",
    "            return_sequences = False\n",
    "        else:\n",
    "            return_sequences = last_lstm_return_sequences\n",
    "        model.add(\n",
    "            LSTM(\n",
    "                units=lstm_units[0],\n",
    "                activation=activation,\n",
    "                return_sequences=return_sequences,\n",
    "                input_shape=(seq_len, n_features),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if single_output:  # Single Step, Direct Multi Step\n",
    "        if dense_units:\n",
    "            for n_units in dense_units:\n",
    "                model.add(Dense(units=n_units, activation=activation))\n",
    "        if dropout > 0:\n",
    "            model.add(Dropout(rate=dropout))\n",
    "        model.add(Dense(1))\n",
    "    else:  # Multiple Output Step\n",
    "        if last_lstm_return_sequences:\n",
    "            model.add(Flatten())\n",
    "        if dense_units:\n",
    "            for n_units in dense_units:\n",
    "                model.add(Dense(units=n_units, activation=activation))\n",
    "        if dropout > 0:\n",
    "            model.add(Dropout(rate=dropout))\n",
    "        model.add(Dense(units=steps))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=MSE, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "\n",
    "ForecastLSTM.build_and_compile_lstm_model = build_and_compile_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b4eed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lstm(\n",
    "    self,\n",
    "    df: pd.DataFrame,\n",
    "    steps: int,\n",
    "    lstm_units: list,\n",
    "    activation: str,\n",
    "    dropout: float = 0,\n",
    "    seq_len: int = 16,\n",
    "    single_output: bool = False,\n",
    "    epochs: int = 200,\n",
    "    batch_size: int = None,\n",
    "    steps_per_epoch: int = None,\n",
    "    learning_rate: float = 0.001,\n",
    "    patience: int = 10,\n",
    "    validation_split: float = 0.3,\n",
    "    last_lstm_return_sequences: bool = False,\n",
    "    dense_units: list = None,\n",
    "    metrics: str = \"mse\",\n",
    "    check_point_path: str = None,\n",
    "    verbose: bool = False,\n",
    "    plot: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    LSTM 기반 모델 훈련을 진행한다.\n",
    "\n",
    "    :param df: DataFrame for model train.\n",
    "    :param steps: Length to predict.\n",
    "    :param lstm_units: LSTM, Dense Layers\n",
    "    :param activation: Activation function for LSTM, Dense Layers.\n",
    "    :param dropout: Dropout ratio between Layers.\n",
    "    :param seq_len: Length of sequences. (Look back window size)\n",
    "    :param single_output: Select whether 'y' is a continuous value or a single value.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(self.random_seed)\n",
    "    tf.random.set_seed(self.random_seed)\n",
    "\n",
    "    # 훈련, 검증 데이터셋 생성\n",
    "    (\n",
    "        self.X_train,\n",
    "        self.y_train,\n",
    "        self.X_val,\n",
    "        self.y_val,\n",
    "    ) = self.split_train_valid_dataset(\n",
    "        df=df,\n",
    "        seq_len=seq_len,\n",
    "        steps=steps,\n",
    "        validation_split=validation_split,\n",
    "        single_output=single_output,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    # LSTM 모델 생성\n",
    "    n_features = df.shape[1] - 1\n",
    "    self.model = self.build_and_compile_lstm_model(\n",
    "        seq_len=seq_len,\n",
    "        n_features=n_features,\n",
    "        lstm_units=lstm_units,\n",
    "        activation=activation,\n",
    "        learning_rate=learning_rate,\n",
    "        dropout=dropout,\n",
    "        steps=steps,\n",
    "        last_lstm_return_sequences=last_lstm_return_sequences,\n",
    "        dense_units=dense_units,\n",
    "        metrics=metrics,\n",
    "        single_output=single_output,\n",
    "    )\n",
    "\n",
    "    # 모델 적합 과정에서 best model 저장\n",
    "    if check_point_path is not None:\n",
    "        # create checkpoint\n",
    "        checkpoint_path = f\"checkpoint/lstm_{check_point_path}.h5\"\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            filepath=checkpoint_path,\n",
    "            save_weights_only=False,\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\",\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        rlr = ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=patience, verbose=verbose\n",
    "        )\n",
    "        callbacks = [checkpoint, EarlyStopping(patience=patience), rlr]\n",
    "    else:\n",
    "        rlr = ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=patience, verbose=verbose\n",
    "        )\n",
    "        callbacks = [EarlyStopping(patience=patience), rlr]\n",
    "\n",
    "    # 모델 훈련\n",
    "    self.history = self.model.fit(\n",
    "        self.X_train,\n",
    "        self.y_train,\n",
    "        batch_size=batch_size,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=(self.X_val, self.y_val),\n",
    "        epochs=epochs,\n",
    "        use_multiprocessing=True,\n",
    "        workers=8,\n",
    "        verbose=verbose,\n",
    "        callbacks=callbacks,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    # 훈련 종료 후 best model 로드\n",
    "    if check_point_path is not None:\n",
    "        self.model.load_weights(f\"checkpoint/lstm_{check_point_path}.h5\")\n",
    "\n",
    "    # 모델링 과정 시각화\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(self.history.history[f\"{metrics}\"])\n",
    "        plt.plot(self.history.history[f\"val_{metrics}\"])\n",
    "        plt.title(\"Performance Metric\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(f\"{metrics}\")\n",
    "        if metrics == \"mape\":\n",
    "            plt.axhline(y=10, xmin=0, xmax=1, color=\"grey\", ls=\"--\", alpha=0.5)\n",
    "        plt.legend([\"Train\", \"Validation\"], loc=\"upper right\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "ForecastLSTM.fit_lstm = fit_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cee81db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_validation_dataset(self) -> pd.DataFrame:\n",
    "    # 검증 데이터셋의 실제 값(y)과, 예측 값(yhat)을 저장할 리스트 생성\n",
    "    y_pred_list, y_val_list = list(), list()\n",
    "    \n",
    "    # 훈련된 모델로 validation dataset에 대한 예측값 생성\n",
    "    for x_val, y_val in zip(self.X_val, self.y_val):\n",
    "        x_val = np.expand_dims(\n",
    "            x_val, axis=0\n",
    "        )  # (seq_len, n_features) -> (1, seq_len, n_features)\n",
    "        y_pred = self.model.predict(x_val)[0]\n",
    "        y_pred_list.extend(y_pred.tolist())\n",
    "        y_val_list.extend(y_val.tolist())\n",
    "    return pd.DataFrame({\"y\": y_val_list, \"yhat\": y_pred_list})\n",
    "\n",
    "\n",
    "ForecastLSTM.forecast_validation_dataset = forecast_validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15d30c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df_fcst: pd.DataFrame) -> dict:\n",
    "    true = df_fcst[\"y\"]\n",
    "    pred = df_fcst[\"yhat\"]\n",
    "\n",
    "    mae = (true - pred).abs().mean()\n",
    "    mape = (true - pred).abs().div(true).mean() * 100\n",
    "    mse = ((true - pred) ** 2).mean()\n",
    "    return {\n",
    "        \"mae\": mae,\n",
    "        \"mape\": mape,\n",
    "        \"mse\": mse,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "764b54cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ROE</th>\n",
       "      <th>영업이익률</th>\n",
       "      <th>부채비율</th>\n",
       "      <th>EPS</th>\n",
       "      <th>순이익률</th>\n",
       "      <th>BPS</th>\n",
       "      <th>종가</th>\n",
       "      <th>PER</th>\n",
       "      <th>PBR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20221231</td>\n",
       "      <td>16.424694</td>\n",
       "      <td>14.352127</td>\n",
       "      <td>26.405922</td>\n",
       "      <td>8057.0</td>\n",
       "      <td>18.414395</td>\n",
       "      <td>5.135684e+04</td>\n",
       "      <td>55300.0</td>\n",
       "      <td>6.863597</td>\n",
       "      <td>1.076780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20211231</td>\n",
       "      <td>13.575704</td>\n",
       "      <td>18.466727</td>\n",
       "      <td>39.921697</td>\n",
       "      <td>5777.0</td>\n",
       "      <td>14.272806</td>\n",
       "      <td>4.413730e+04</td>\n",
       "      <td>78300.0</td>\n",
       "      <td>13.553748</td>\n",
       "      <td>1.774010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20201231</td>\n",
       "      <td>9.709985</td>\n",
       "      <td>15.199668</td>\n",
       "      <td>37.067743</td>\n",
       "      <td>3841.0</td>\n",
       "      <td>11.151627</td>\n",
       "      <td>4.013644e+04</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>21.088258</td>\n",
       "      <td>2.018116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20191231</td>\n",
       "      <td>8.509015</td>\n",
       "      <td>12.052258</td>\n",
       "      <td>34.115921</td>\n",
       "      <td>3166.0</td>\n",
       "      <td>9.435235</td>\n",
       "      <td>3.828532e+04</td>\n",
       "      <td>55800.0</td>\n",
       "      <td>17.624763</td>\n",
       "      <td>1.457478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20181231</td>\n",
       "      <td>18.204228</td>\n",
       "      <td>24.156511</td>\n",
       "      <td>36.973922</td>\n",
       "      <td>6461.0</td>\n",
       "      <td>18.191164</td>\n",
       "      <td>3.609738e+04</td>\n",
       "      <td>38700.0</td>\n",
       "      <td>5.989785</td>\n",
       "      <td>1.072100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20171231</td>\n",
       "      <td>19.467028</td>\n",
       "      <td>22.391716</td>\n",
       "      <td>40.682587</td>\n",
       "      <td>5997.0</td>\n",
       "      <td>17.608966</td>\n",
       "      <td>3.049074e+04</td>\n",
       "      <td>50960.0</td>\n",
       "      <td>8.497582</td>\n",
       "      <td>1.671327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20161231</td>\n",
       "      <td>11.715457</td>\n",
       "      <td>14.485136</td>\n",
       "      <td>35.867643</td>\n",
       "      <td>3159.0</td>\n",
       "      <td>11.257967</td>\n",
       "      <td>2.682248e+04</td>\n",
       "      <td>36040.0</td>\n",
       "      <td>11.408674</td>\n",
       "      <td>1.343649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20151231</td>\n",
       "      <td>10.245763</td>\n",
       "      <td>13.163710</td>\n",
       "      <td>35.250634</td>\n",
       "      <td>126305.0</td>\n",
       "      <td>9.499035</td>\n",
       "      <td>1.186568e+06</td>\n",
       "      <td>25200.0</td>\n",
       "      <td>0.199517</td>\n",
       "      <td>0.021238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20141231</td>\n",
       "      <td>13.726899</td>\n",
       "      <td>12.135958</td>\n",
       "      <td>37.084563</td>\n",
       "      <td>153105.0</td>\n",
       "      <td>11.345140</td>\n",
       "      <td>1.100058e+06</td>\n",
       "      <td>26540.0</td>\n",
       "      <td>0.173345</td>\n",
       "      <td>0.024126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20131231</td>\n",
       "      <td>20.384758</td>\n",
       "      <td>16.084911</td>\n",
       "      <td>42.701448</td>\n",
       "      <td>197841.0</td>\n",
       "      <td>13.325641</td>\n",
       "      <td>9.738982e+05</td>\n",
       "      <td>27440.0</td>\n",
       "      <td>0.138697</td>\n",
       "      <td>0.028175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        ROE      영업이익률       부채비율       EPS       순이익률  \\\n",
       "0    20221231  16.424694  14.352127  26.405922    8057.0  18.414395   \n",
       "1    20211231  13.575704  18.466727  39.921697    5777.0  14.272806   \n",
       "2    20201231   9.709985  15.199668  37.067743    3841.0  11.151627   \n",
       "3    20191231   8.509015  12.052258  34.115921    3166.0   9.435235   \n",
       "4    20181231  18.204228  24.156511  36.973922    6461.0  18.191164   \n",
       "5    20171231  19.467028  22.391716  40.682587    5997.0  17.608966   \n",
       "6    20161231  11.715457  14.485136  35.867643    3159.0  11.257967   \n",
       "7    20151231  10.245763  13.163710  35.250634  126305.0   9.499035   \n",
       "8    20141231  13.726899  12.135958  37.084563  153105.0  11.345140   \n",
       "9    20131231  20.384758  16.084911  42.701448  197841.0  13.325641   \n",
       "\n",
       "            BPS       종가        PER       PBR  \n",
       "0  5.135684e+04  55300.0   6.863597  1.076780  \n",
       "1  4.413730e+04  78300.0  13.553748  1.774010  \n",
       "2  4.013644e+04  81000.0  21.088258  2.018116  \n",
       "3  3.828532e+04  55800.0  17.624763  1.457478  \n",
       "4  3.609738e+04  38700.0   5.989785  1.072100  \n",
       "5  3.049074e+04  50960.0   8.497582  1.671327  \n",
       "6  2.682248e+04  36040.0  11.408674  1.343649  \n",
       "7  1.186568e+06  25200.0   0.199517  0.021238  \n",
       "8  1.100058e+06  26540.0   0.173345  0.024126  \n",
       "9  9.738982e+05  27440.0   0.138697  0.028175  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('데이터셋.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5028d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ROE', '영업이익률', '부채비율', 'EPS', '순이익률', 'BPS', '종가', 'PER',\n",
       "       'PBR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b86239fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Unnamed: 0'],axis=1)\n",
    "df = df.rename(columns={'종가' : 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76b9d3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   ROE     10 non-null     float64\n",
      " 1   영업이익률   10 non-null     float64\n",
      " 2   부채비율    10 non-null     float64\n",
      " 3   EPS     10 non-null     float64\n",
      " 4   순이익률    10 non-null     float64\n",
      " 5   BPS     10 non-null     float64\n",
      " 6   y       10 non-null     float64\n",
      " 7   PER     10 non-null     float64\n",
      " 8   PBR     10 non-null     float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 848.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03b6ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Unnamed: 0', 'PER','ROE', '영업이익률', '부채비율', 'EPS', '순이익률', 'BPS'],axis=1)\n",
    "df = df.rename(columns={'종가' : 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa41e7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   y       10 non-null     float64\n",
      " 1   PBR     10 non-null     float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 288.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7138e84",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m## 4) 모델 훈련\u001b[39;00m\n\u001b[0;32m     26\u001b[0m fl \u001b[38;5;241m=\u001b[39m ForecastLSTM()\n\u001b[1;32m---> 27\u001b[0m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_lstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43msingle_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlstm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m## 5) Validation dataset 예측 성능\u001b[39;00m\n\u001b[0;32m     36\u001b[0m df_fcst_val \u001b[38;5;241m=\u001b[39m fl\u001b[38;5;241m.\u001b[39mforecast_validation_dataset()\n",
      "Cell \u001b[1;32mIn[7], line 44\u001b[0m, in \u001b[0;36mfit_lstm\u001b[1;34m(self, df, steps, lstm_units, activation, dropout, seq_len, single_output, epochs, batch_size, steps_per_epoch, learning_rate, patience, validation_split, last_lstm_return_sequences, dense_units, metrics, check_point_path, verbose, plot)\u001b[0m\n\u001b[0;32m     36\u001b[0m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mset_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_seed)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# 훈련, 검증 데이터셋 생성\u001b[39;00m\n\u001b[0;32m     39\u001b[0m (\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train,\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train,\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_val,\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_val,\n\u001b[1;32m---> 44\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_train_valid_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43msingle_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# LSTM 모델 생성\u001b[39;00m\n\u001b[0;32m     54\u001b[0m n_features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36msplit_train_valid_dataset\u001b[1;34m(self, df, seq_len, steps, single_output, validation_split, verbose)\u001b[0m\n\u001b[0;32m     22\u001b[0m dataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X)\n\u001b[0;32m     23\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(dataset_size \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m validation_split))\n\u001b[1;32m---> 24\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m, y[:train_size, :]\n\u001b[0;32m     25\u001b[0m X_val, y_val \u001b[38;5;241m=\u001b[39m X[train_size:, :], y[train_size:, :]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "## 1) Train, Test 데이터 분리\n",
    "#cutoff = \"2022-01-01\"\n",
    "df_train = df[df.index < 7]\n",
    "df_test = df[df.index >= 7]\n",
    "\n",
    "## 2) Sequence Length, 예측 기간(Step), Single Output 여부 등 정의\n",
    "seq_len = 5  # 과거 5주의 데이터를 feature로 사용\n",
    "steps = 5  # 향후 5주의 y를 예측\n",
    "single_output = False  # 향후 5주차의 시점만이 아닌, 1~5주 모두 예측\n",
    "metrics = \"mse\"  # 모델 성능 지표\n",
    "\n",
    "## 3) LSTM 하이퍼파라미터 정의\n",
    "lstm_params = {\n",
    "    \"seq_len\": seq_len,\n",
    "    \"epochs\": 300,  # epochs 반복 횟수\n",
    "    \"patience\": 30,  # early stopping 조건\n",
    "    \"steps_per_epoch\": 5,  # 1 epochs 시 dataset을 5개로 분할하여 학습\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"lstm_units\": [64, 32],  # Dense Layer: 2, Unit: (64, 32)\n",
    "    \"activation\": \"relu\",\n",
    "    \"dropout\": 0,\n",
    "    \"validation_split\": 0.3,  # 검증 데이터셋 30%\n",
    "}\n",
    "\n",
    "## 4) 모델 훈련\n",
    "fl = ForecastLSTM()\n",
    "fl.fit_lstm(\n",
    "    df=df_train,\n",
    "    steps=steps,\n",
    "    single_output=single_output,\n",
    "    metrics=metrics,\n",
    "    **lstm_params,\n",
    ")\n",
    "\n",
    "## 5) Validation dataset 예측 성능\n",
    "df_fcst_val = fl.forecast_validation_dataset()\n",
    "val_loss = calculate_metrics(df_fcst=df_fcst_val)[metrics]\n",
    "print(f\"{metrics} of validation dataset: {val_loss.round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31ccc94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'EUC-KR', 'confidence': 0.99, 'language': 'Korean'}\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "\n",
    "with open('데이터셋.csv', 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(10000))\n",
    "\n",
    "# check what the character encoding might be\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c056d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
